{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chromedriver = \"/Users/jaykim/Downloads/chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables that will save data from the web scraping\n",
    "yeartrim=[]\n",
    "price=[]\n",
    "miles=[]\n",
    "exterior=[]\n",
    "interior=[]\n",
    "transmission=[]\n",
    "drivetrain=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chromedriver)\n",
    "time.sleep(1);\n",
    "\n",
    "# add1 and add2 will be used as links to go through pages on cars.com\n",
    "add1='https://www.cars.com/for-sale/searchresults.action/?mdId=20823&mkId=20017&page='  \n",
    "add2='&perPage=100&rd=99999&searchSource=PAGINATION&sort=relevance&stkTypId=28881&zc=98109'   \n",
    "\n",
    "reference=['Exterior','Interior','Transmission','Drivetrain']*100   # There are missing information on web page. This variable will clean them up.\n",
    "for k in range(21):    # Scraping 21 pages\n",
    "    url=add1+str(k+1)+add2\n",
    "    driver.get(url)\n",
    "    time.sleep(1);\n",
    "\n",
    "    a=driver.find_elements_by_xpath('//h2[@class=\"cui-delta listing-row__title\"]')   # getting info from the webpage\n",
    "    b=driver.find_elements_by_xpath('//span[@class=\"listing-row__price\"]')           # getting info from the webpage\n",
    "    c=driver.find_elements_by_xpath('//span[@class=\"listing-row__mileage\"]')         # getting info from the webpage\n",
    "    d=driver.find_elements_by_xpath('//span[@class=\"listing-row__meta-item\"]')       # getting info from the webpage\n",
    "     \n",
    "    for i in range(len(a)):          \n",
    "        yeartrim.append(a[i].text)\n",
    "        price.append(b[i].text)\n",
    "        miles.append(c[i].text)\n",
    "\n",
    "    for i in range(len(reference)):   # To account for missing values\n",
    "        if reference[i] not in d[i].text:\n",
    "            d.insert(i, d[i-1])\n",
    "        \n",
    "    for i in range(len(d)//4):\n",
    "        exterior.append(d[4*i].text)\n",
    "        interior.append(d[4*i+1].text)\n",
    "        transmission.append(d[4*i+2].text)\n",
    "        drivetrain.append(d[4*i+3].text)\n",
    "    print(len(d),',',len(exterior),',',len(interior),',',len(transmission),',',len(drivetrain))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label=['yeartrim','price','miles','exterior','interior','transmission','drivetrain']   # Create DataFrame\n",
    "matrix = np.matrix([yeartrim, price, miles, exterior, interior, transmission, drivetrain])\n",
    "df = pd.DataFrame(data=matrix.T, columns=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look for missing information and remove rows if there are\n",
    "\n",
    "df['bad'] = df.interior.str.split(': ').str.get(0)        \n",
    "df3 = df.loc[df.bad == 'Interior Color']\n",
    "len(df3)\n",
    "df3['bad2'] = df3.exterior.str.split(': ').str.get(0)\n",
    "df4 = df3.loc[df3.bad2 == 'Exterior Color']\n",
    "len(df4)\n",
    "df5 = df4.drop(['bad','bad2','bad3'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yeartrim = df5.yeartrim.tolist()\n",
    "pr=df5.price.tolist()\n",
    "mi=df5.miles.tolist()\n",
    "exte=df5.exterior.tolist()\n",
    "inte=df5.interior.tolist()\n",
    "trans=df5.transmission.tolist()\n",
    "drive=df5.drivetrain.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up data\n",
    "\n",
    "year = [int(yeartrim[i].split(' ')[1]) for i in range(len(yeartrim))]\n",
    "trim = [yeartrim[i].split(' ')[-1] for i in range(len(yeartrim))]\n",
    "for i in range(len(pr)):\n",
    "    if pr[i] == 'Not Priced':\n",
    "        pr[i] = pr[i].replace('Not Priced','$0,')\n",
    "price = [int(pr[i].replace('$','').replace(',','')) for i in range(len(pr))]\n",
    "miles = [int(mi[i].split(': ')[-1].replace(',','')) for i in range(len(mi))]\n",
    "exterior = [exte[i].split(': ')[-1] for i in range(len(exte))]\n",
    "interior = [inte[i].split(': ')[-1] for i in range(len(inte))]\n",
    "transmission = [trans[i].split(': ')[-1] for i in range(len(trans))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Put all data into DataFrame\n",
    "\n",
    "label=['year','trim','price','miles','exterior','interior','transmission']\n",
    "data1 =[year,trim,price,miles,exterior,interior,transmission]\n",
    "\n",
    "df7=pd.DataFrame(data=data1, columns=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame.copy(df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove one outlier\n",
    "df2=df.loc[df.price<30000]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "plt.subplot(3,1,1)\n",
    "plt.hist(df2.year, bins=17)\n",
    "plt.title('Year', fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.subplot(3,1,2)\n",
    "plt.hist(df2.miles, bins=17)\n",
    "plt.title('Miles', fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.subplot(3,1,3)\n",
    "plt.hist(df2.price, bins=17)\n",
    "plt.title('Price', fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(3,1,1)\n",
    "plt.scatter(df2.year, df2.miles)\n",
    "plt.title('year  miles')\n",
    "plt.subplot(3,1,2)\n",
    "plt.scatter(df2.miles, df2.price)\n",
    "plt.title('miles  price')\n",
    "plt.subplot(3,1,3)\n",
    "plt.scatter(df2.year, df2.price)\n",
    "plt.title('year  price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Categorical variables have too many features and typos. This will clean up data and simplyfy the categories.\n",
    "# For transmission\n",
    "\n",
    "df2.transmission.replace('1-Speed CVT w/OD','Automatic CVT',inplace=True)\n",
    "df2.transmission.replace('CVT w/OD','Automatic CVT',inplace=True)\n",
    "df2.transmission.replace('continuously variable automatic','Automatic CVT',inplace=True)\n",
    "df2.transmission.replace('5-Speed Automatic','Automatic',inplace=True)\n",
    "df2.transmission.replace('6-Speed Manual','Manual',inplace=True)\n",
    "df2.transmission.replace('5-Speed Manual','Manual',inplace=True)\n",
    "df2.transmission.replace('4-Speed Automatic','Automatic',inplace=True)\n",
    "df2.transmission.replace('Variable','Automatic CVT',inplace=True)\n",
    "df2.transmission.replace('6-Speed Manual w/OD','Manual',inplace=True)\n",
    "df2.transmission.replace('5 speed automatic','Automatic',inplace=True)\n",
    "df2.transmission.replace('1-Speed Variable','Automatic CVT',inplace=True)\n",
    "df2.transmission.replace('5-Speed Manual w/OD','Manual',inplace=True)\n",
    "df2.transmission.replace('4 speed automatic','Automatic',inplace=True)\n",
    "df2.transmission.replace('4-Speed Electronic Automatic','Automatic',inplace=True)\n",
    "df2.transmission.replace('Auto CD, REAR CAM, CLEAN CAR, BLUETOOTH','Automatic',inplace=True)\n",
    "df2.transmission.replace('6 speed manual','Manual',inplace=True)\n",
    "df2.transmission.replace('6-Speed Automatic','Automatic',inplace=True)\n",
    "df2.transmission.replace('Close-Ratio 6-Speed Manual','Manual',inplace=True)\n",
    "df2.transmission.replace('Automatic CVT','CVT',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For interior color\n",
    "\n",
    "df2.interior.replace('GRAY','Gray',inplace=True)\n",
    "df2.interior.replace('gray','Gray',inplace=True)\n",
    "df2.interior.replace('Stone Gray','Gray',inplace=True)\n",
    "df2.interior.replace('Stone','Gray',inplace=True)\n",
    "df2.interior.replace('Light Gray','Gray',inplace=True)\n",
    "df2.interior.replace('Slate Gray','Gray',inplace=True)\n",
    "df2.interior.replace('Black / Gray','Gray / Black',inplace=True)\n",
    "df2.interior.replace('Black/Gray','Gray / Black',inplace=True)\n",
    "df2.interior.replace('Black / Red','Black/Red',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For trim\n",
    "\n",
    "df2.trim.replace('EX-L','EX',inplace=True)\n",
    "df2.trim.replace('EX-T','EX',inplace=True)\n",
    "df2.trim.replace('LX-S','LX',inplace=True)\n",
    "df2.trim.replace('LX-P','LX',inplace=True)\n",
    "df2.trim.replace('DX-VP','DX',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For exterior color\n",
    "\n",
    "df2.exterior.replace('Taffeta White','White',inplace=True)\n",
    "df2.exterior.replace('White Orchid','White',inplace=True)\n",
    "df2.exterior.replace('Galaxy Gray Metallic','Gray',inplace=True)\n",
    "df2.exterior.replace('Sonic Gray Pearl','Gray',inplace=True)\n",
    "df2.exterior.replace('Dark Gray','Gray',inplace=True)\n",
    "df2.exterior.replace('Ghost Gray','Gray',inplace=True)\n",
    "df2.exterior.replace('Atomic Blue Metallic','Blue',inplace=True)\n",
    "df2.exterior.replace('Aegean Blue Metallic','Blue',inplace=True)\n",
    "df2.exterior.replace('Dyno Blue Pearl','Blue',inplace=True)\n",
    "df2.exterior.replace('Royal Blue Pearl','Blue',inplace=True)\n",
    "df2.exterior.replace('Dyno Blue Pearl Ii','Blue',inplace=True)\n",
    "df2.exterior.replace('Aegean Blue','Blue',inplace=True)\n",
    "df2.exterior.replace('Dyno Blue','Blue',inplace=True)\n",
    "df2.exterior.replace('Blue Pearl','Blue',inplace=True)\n",
    "df2.exterior.replace('Fiji Blue Pearl','Blue',inplace=True)\n",
    "df2.exterior.replace('Cosmic Blue Metallic','Blue',inplace=True)\n",
    "df2.exterior.replace('Tango Red Pearl','Red',inplace=True)\n",
    "df2.exterior.replace('Dark Red','Red',inplace=True)\n",
    "df2.exterior.replace('Rally Red','Red',inplace=True)\n",
    "df2.exterior.replace('Milano Red','Red',inplace=True)\n",
    "df2.exterior.replace('Crimson Pearl Red','Red',inplace=True)\n",
    "df2.exterior.replace('Rallye Red','Red',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.exterior.replace('Alabaster Silver Metallic','Silver',inplace=True)\n",
    "df2.exterior.replace('Lunar Silver Metallic','Silver',inplace=True)\n",
    "df2.exterior.replace('Satin Silver Metallic','Silver',inplace=True)\n",
    "df2.exterior.replace('Silver Mist','Silver',inplace=True)\n",
    "df2.exterior.replace('Alabaster Silver','Silver',inplace=True)\n",
    "df2.exterior.replace('Silver Metallic','Silver',inplace=True)\n",
    "df2.exterior.replace('Lunar Silver','Silver',inplace=True)\n",
    "df2.exterior.replace('White Orchid Pearl','White',inplace=True)\n",
    "df2.exterior.replace('Crystal Black Pearl','Black',inplace=True)\n",
    "df2.exterior.replace('Nighthawk Black Pearl','Black',inplace=True)\n",
    "df2.exterior.replace('Crystal Black','Black',inplace=True)\n",
    "df2.exterior.replace('Super Black','Black',inplace=True)\n",
    "df2.exterior.replace('Nighthawk Black','Black',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.exterior.replace('Modern Steel Metallic','Metallic',inplace=True)\n",
    "df2.exterior.replace('Urban Titanium Metallic','Metallic',inplace=True)\n",
    "df2.exterior.replace('Polished Metal Metallic','Metallic',inplace=True)\n",
    "df2.exterior.replace('Polished Metal','Metallic',inplace=True)\n",
    "df2.exterior.replace('Modern Steel','Metallic',inplace=True)\n",
    "df2.exterior.replace('Urban Titanium','Metallic',inplace=True)\n",
    "df2.exterior.replace('Kona Coffee Metallic','Metallic',inplace=True)\n",
    "df2.exterior.replace('Magnesium Metallic','Metallic',inplace=True)\n",
    "df2.exterior.replace('Borrego Beige Metallic','Metallic',inplace=True)\n",
    "df2.exterior.replace('Shoreline Mist Metallic','Metallic',inplace=True)\n",
    "df2.exterior.replace('Titanium Metallic','Metallic',inplace=True)\n",
    "df2.exterior.replace('Cool Mist Metallic','Metallic',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a category 'Other' to merge the minor categories\n",
    "\n",
    "index_exterior = df2.exterior.value_counts()[:8]\n",
    "for i in range(len(df2)):\n",
    "    if df2.exterior[i] not in index_exterior:\n",
    "        df2.exterior.replace(df2.exterior[i],'Other',inplace=True)\n",
    "\n",
    "index_interior = df2.interior.value_counts()[:9]\n",
    "for i in range(len(df2)):\n",
    "    if df2.interior[i] not in index_interior:\n",
    "        df2.interior.replace(df2.interior[i],'Other',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy variables for categorical data and adding more complexity for numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=df2[['year','miles']]\n",
    "\n",
    "# Generate dummy variables for categorical data\n",
    "\n",
    "dummy_trim=pd.get_dummies(df2.trim, prefix='trim')#, drop_first=True)\n",
    "dummy_exterior=pd.get_dummies(df2.exterior, prefix='exterior')#, drop_first=True)\n",
    "dummy_interior=pd.get_dummies(df2.interior, prefix='interior')#, drop_first=True)\n",
    "dummy_transmission=pd.get_dummies(df2.transmission, prefix='transmission')#, drop_first=True)\n",
    "\n",
    "X = X.join(dummy_trim)\n",
    "X = X.join(dummy_exterior)\n",
    "X = X.join(dummy_interior)\n",
    "X = X.join(dummy_transmission)\n",
    "\n",
    "y=df2.price.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,random_state=42)\n",
    "\n",
    "# Log transformation for year and miles to remove the bias from data\n",
    "\n",
    "X_train['year_log'] = np.log(X_train.year)\n",
    "X_train['miles_log'] = np.log(X_train.miles)\n",
    "X_train = X_train.drop(['year','miles'],axis=1)\n",
    "\n",
    "X_test['year_log'] = np.log(X_test.year)\n",
    "X_test['miles_log'] = np.log(X_test.miles)\n",
    "X_test = X_test.drop(['year','miles'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding more complexity for year and miles to account for nonlinear relationship\n",
    "\n",
    "X2_train = X_train.filter(['year_log','miles_log'], axis=1)\n",
    "X2_test = X_test.filter(['year_log','miles_log'], axis=1)\n",
    "\n",
    "p = PolynomialFeatures(2)\n",
    "X2_train = p.fit_transform(X2_train)\n",
    "X2_test = p.transform(X2_test)\n",
    "\n",
    "# Normalization\n",
    "s = StandardScaler()\n",
    "X2_train_co = s.fit_transform(X2_train)\n",
    "X2_test_co = s.transform(X2_test)\n",
    "\n",
    "# Formatting data\n",
    "col = ['col'+str(i) for i in range(6)]\n",
    "X2_train_co = pd.DataFrame(columns=col, data=X2_train_co)\n",
    "X2_test_co = pd.DataFrame(columns=col, data=X2_test_co)\n",
    "\n",
    "X2_train_complex = pd.DataFrame.copy(X_train)\n",
    "X2_test_complex = pd.DataFrame.copy(X_test)\n",
    "\n",
    "X2_train_complex = X2_train_complex.reset_index(drop=True)\n",
    "X2_test_complex = X2_test_complex.reset_index(drop=True)\n",
    "\n",
    "X2_train_complex = X2_train_complex.join(X2_train_co)\n",
    "X2_test_complex = X2_test_complex.join(X2_test_co)\n",
    "\n",
    "X2_train_complex = X2_train_complex.drop(['year_log','miles_log'],axis=1)\n",
    "X2_test_complex = X2_test_complex.drop(['year_log','miles_log'],axis=1)\n",
    "X2_train_complex.col0.replace(0,1,inplace=True)\n",
    "\n",
    "X2_train_complex.rename(columns={'col0': 'intercept', 'col1': 'year','col2':'mile','col3':'year_2','col4':'yearmile','col5':'mile_2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regularization with Ridge regression\n",
    "\n",
    "est = make_pipeline(RidgeCV(cv=3,alphas=(1e-8,1e-4,1e0,1e4,1e8)))\n",
    "est.fit(X2_train_complex, y_train)\n",
    "\n",
    "print('Train R^2: ',est.score(X2_train_complex, y_train))\n",
    "print('Train RMSSE:', np.sqrt(mean_squared_error(y_train, est.predict(X2_train_complex))))\n",
    "print('Test R^2: ', est.score(X2_test_complex, y_test))\n",
    "print('Test RMSSE:', np.sqrt(mean_squared_error(y_test, est.predict(X2_test_complex))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.scatter(y_test, est.predict(X2_test_complex), label='Data')\n",
    "a=[0,25000]\n",
    "b=[0,25000]\n",
    "plt.plot(a,b, color='red', label='Perfect match')\n",
    "plt.title('Price Prediction', fontsize=30)\n",
    "plt.xlabel('Actual Price ($)',fontsize=20)\n",
    "plt.ylabel('Predicted Price ($)',fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.scatter(est.predict(X2_train_complex), est.predict(X2_train_complex) - y_train, c='b',alpha = 0.5, label='Train')\n",
    "plt.scatter(est.predict(X2_test_complex), est.predict(X2_test_complex) - y_test, c='g',alpha = 0.5, label='Test')\n",
    "plt.title('Residual scatter plot for Train (blue) and Test (green) data', fontsize=30)\n",
    "plt.xlabel('Predicted Price ($)',fontsize=20)\n",
    "plt.ylabel('Residual ($)',fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlim([-5000,25000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate p-values with Statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X3_train_complex = X2_train_complex.reset_index(drop=True)\n",
    "stats_y = pd.DataFrame(y_train, columns=['price'])\n",
    "X3_train_complex = X3_train_complex.join(stats_y)\n",
    "\n",
    "# Generate equations for Statsmodel\n",
    "equ='price ~ ' + str(X3_train_complex.columns[0])\n",
    "for i in range(1,X3_train_complex.shape[1]-1):\n",
    "    equ += ' + '\n",
    "    equ += str(X3_train_complex.columns[i])\n",
    "    \n",
    "y, X = patsy.dmatrices(equ, data=X3_train_complex, return_type=\"dataframe\")\n",
    "model = sm.OLS(y, X)\n",
    "fit = model.fit()\n",
    "\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study with different degrees of polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r2_train=[]\n",
    "r2_test=[]\n",
    "rmse_train=[]\n",
    "rmse_test=[]\n",
    "index=[]\n",
    "for k in range(2,10):  # Exploring different degrees from 2 to 9\n",
    "    p = PolynomialFeatures(k)\n",
    "    X3_train = p.fit_transform(X2_train)\n",
    "    X3_test = p.transform(X2_test)\n",
    "    s = StandardScaler()\n",
    "    X1_train_co = s.fit_transform(X3_train)\n",
    "    X1_test_co = s.transform(X3_test)\n",
    "\n",
    "    X2_train_co = pd.DataFrame( data=X1_train_co) #columns=col\n",
    "    X2_test_co = pd.DataFrame(data=X1_test_co) #columns=col\n",
    "\n",
    "    X2_train_complex = pd.DataFrame.copy(X_train)\n",
    "    X2_test_complex = pd.DataFrame.copy(X_test)\n",
    "\n",
    "    X2_train_complex = X2_train_complex.reset_index(drop=True)\n",
    "    X2_test_complex = X2_test_complex.reset_index(drop=True)\n",
    "\n",
    "    X2_train_complex = X2_train_complex.join(X2_train_co)\n",
    "    X2_test_complex = X2_test_complex.join(X2_test_co)\n",
    "    X2_train_complex = X2_train_complex.drop(['year_log','miles_log'],axis=1)\n",
    "    X2_test_complex = X2_test_complex.drop(['year_log','miles_log'],axis=1)\n",
    "\n",
    "    est = make_pipeline(RidgeCV(cv=3,alphas=(1e-8,1e-4,1e0,1e4,1e8)))\n",
    "\n",
    "    est.fit(X2_train_complex, y_train)\n",
    "    print('complexity =', k)\n",
    "    print('Train R^2: ',est.score(X2_train_complex, y_train))\n",
    "    print('Train RMSSE:', np.sqrt(mean_squared_error(y_train, est.predict(X2_train_complex))))\n",
    "    print('Test R^2: ', est.score(X2_test_complex, y_test))\n",
    "    print('Test RMSSE:', np.sqrt(mean_squared_error(y_test, est.predict(X2_test_complex))))\n",
    "    print('----------')\n",
    "    \n",
    "    r2_train.append(est.score(X2_train_complex, y_train))\n",
    "    r2_test.append(est.score(X2_test_complex, y_test))\n",
    "    rmse_train.append(np.sqrt(mean_squared_error(y_train, est.predict(X2_train_complex))))\n",
    "    rmse_test.append(np.sqrt(mean_squared_error(y_test, est.predict(X2_test_complex))))\n",
    "    index.append(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wife_car_final=np.array([1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,1,-0.5111072,  0.65581954, -0.51126046,  0.65604447,0.64537731])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.dot(fit.params,wife_car_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
