{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chromedriver = \"/Users/jaykim/Downloads/chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable assaignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variables that will save data from the web scraping\n",
    "yeartrim=[]\n",
    "price=[]\n",
    "miles=[]\n",
    "exterior=[]\n",
    "interior=[]\n",
    "transmission=[]\n",
    "drivetrain=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(chromedriver)\n",
    "time.sleep(1);\n",
    "\n",
    "# add1 and add2 will be used as links to go through pages on cars.com\n",
    "add1='https://www.cars.com/for-sale/searchresults.action/?mdId=20823&mkId=20017&page='  \n",
    "add2='&perPage=100&rd=99999&searchSource=PAGINATION&sort=relevance&stkTypId=28881&zc=98109'   \n",
    "\n",
    "# There are missing information on web page. This variable will clean them up.\n",
    "reference=['Exterior','Interior','Transmission','Drivetrain']*100   \n",
    "\n",
    "for k in range(21):    # Scraping 21 pages\n",
    "    url=add1+str(k+1)+add2\n",
    "    driver.get(url)\n",
    "    time.sleep(1);\n",
    "\n",
    "    a=driver.find_elements_by_xpath('//h2[@class=\"cui-delta listing-row__title\"]')   \n",
    "    b=driver.find_elements_by_xpath('//span[@class=\"listing-row__price\"]')           \n",
    "    c=driver.find_elements_by_xpath('//span[@class=\"listing-row__mileage\"]')         \n",
    "    d=driver.find_elements_by_xpath('//span[@class=\"listing-row__meta-item\"]')       \n",
    "     \n",
    "    for i in range(len(a)):          \n",
    "        yeartrim.append(a[i].text)\n",
    "        price.append(b[i].text)\n",
    "        miles.append(c[i].text)\n",
    "\n",
    "    for i in range(len(reference)):   # To account for missing values\n",
    "        if reference[i] not in d[i].text:\n",
    "            d.insert(i, d[i-1])\n",
    "        \n",
    "    for i in range(len(d)//4):\n",
    "        exterior.append(d[4*i].text)\n",
    "        interior.append(d[4*i+1].text)\n",
    "        transmission.append(d[4*i+2].text)\n",
    "        drivetrain.append(d[4*i+3].text)\n",
    "    print(len(d),',',len(exterior),',',len(interior),',',len(transmission),',',len(drivetrain))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dataframe with the scaped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label=['yeartrim','price','miles','exterior','interior','transmission','drivetrain']   # Create DataFrame\n",
    "matrix = np.matrix([yeartrim, price, miles, exterior, interior, transmission, drivetrain])\n",
    "df = pd.DataFrame(data=matrix.T, columns=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning on missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    # Look for missing information and remove rows if there are\n",
    "    df['bad'] = df.interior.str.split(': ').str.get(0)        \n",
    "    df = df.loc[df.bad == 'Interior Color']\n",
    "\n",
    "    df['bad2'] = df.exterior.str.split(': ').str.get(0)\n",
    "    df = df.loc[df.bad2 == 'Exterior Color']\n",
    "\n",
    "    df = df.drop(['bad','bad2'],axis=1)\n",
    "\n",
    "    yeartrim = df.yeartrim.tolist()\n",
    "    pr=df.price.tolist()\n",
    "    mi=df.miles.tolist()\n",
    "    exte=df.exterior.tolist()\n",
    "    inte=df.interior.tolist()\n",
    "    trans=df.transmission.tolist()\n",
    "    drive=df.drivetrain.tolist()\n",
    "\n",
    "    # Clean up data\n",
    "    year = [int(yeartrim[i].split(' ')[1]) for i in range(len(yeartrim))]\n",
    "    trim = [yeartrim[i].split(' ')[-1] for i in range(len(yeartrim))]\n",
    "    for i in range(len(pr)):\n",
    "        if pr[i] == 'Not Priced':\n",
    "            pr[i] = pr[i].replace('Not Priced','$0,')\n",
    "    price = [int(pr[i].replace('$','').replace(',','')) for i in range(len(pr))]\n",
    "    miles = [int(mi[i].split(': ')[-1].replace(',','')) for i in range(len(mi))]\n",
    "    exterior = [exte[i].split(': ')[-1] for i in range(len(exte))]\n",
    "    interior = [inte[i].split(': ')[-1] for i in range(len(inte))]\n",
    "    transmission = [trans[i].split(': ')[-1] for i in range(len(trans))]\n",
    "\n",
    "    # Put all data into DataFrame\n",
    "    label=['year','trim','price','miles','exterior','interior','transmission']\n",
    "    data1 =[year,trim,price,miles,exterior,interior,transmission]\n",
    "\n",
    "    return pd.DataFrame(data=data1, columns=label)\n",
    "\n",
    "df = data_cleaning(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "plt.subplot(3,1,1)\n",
    "plt.hist(df2.year, bins=17)\n",
    "plt.title('Year', fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.subplot(3,1,2)\n",
    "plt.hist(df2.miles, bins=17)\n",
    "plt.title('Miles', fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.subplot(3,1,3)\n",
    "plt.hist(df2.price, bins=17)\n",
    "plt.title('Price', fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(3,1,1)\n",
    "plt.scatter(df2.year, df2.miles)\n",
    "plt.title('year  miles')\n",
    "plt.subplot(3,1,2)\n",
    "plt.scatter(df2.miles, df2.price)\n",
    "plt.title('miles  price')\n",
    "plt.subplot(3,1,3)\n",
    "plt.scatter(df2.year, df2.price)\n",
    "plt.title('year  price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning on categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_clean_category(df2):\n",
    "    # Categorical variables have too many features and typos. This will clean up data and simplyfy the categories.\n",
    "\n",
    "    # For transmission\n",
    "    df2.transmission.replace('1-Speed CVT w/OD','Automatic CVT',inplace=True)\n",
    "    df2.transmission.replace('CVT w/OD','Automatic CVT',inplace=True)\n",
    "    df2.transmission.replace('continuously variable automatic','Automatic CVT',inplace=True)\n",
    "    df2.transmission.replace('5-Speed Automatic','Automatic',inplace=True)\n",
    "    df2.transmission.replace('6-Speed Manual','Manual',inplace=True)\n",
    "    df2.transmission.replace('5-Speed Manual','Manual',inplace=True)\n",
    "    df2.transmission.replace('4-Speed Automatic','Automatic',inplace=True)\n",
    "\n",
    "    # For interior color\n",
    "    df2.interior.replace('GRAY','Gray',inplace=True)\n",
    "    df2.interior.replace('gray','Gray',inplace=True)\n",
    "    df2.interior.replace('Stone Gray','Gray',inplace=True)\n",
    "    df2.interior.replace('Stone','Gray',inplace=True)\n",
    "    df2.interior.replace('Light Gray','Gray',inplace=True)\n",
    "    df2.interior.replace('Slate Gray','Gray',inplace=True)\n",
    "    df2.interior.replace('Black / Gray','Gray / Black',inplace=True)\n",
    "    df2.interior.replace('Black/Gray','Gray / Black',inplace=True)\n",
    "    df2.interior.replace('Black / Red','Black/Red',inplace=True)\n",
    "\n",
    "    # For trim\n",
    "    df2.trim.replace('EX-L','EX',inplace=True)\n",
    "    df2.trim.replace('EX-T','EX',inplace=True)\n",
    "    df2.trim.replace('LX-S','LX',inplace=True)\n",
    "    df2.trim.replace('LX-P','LX',inplace=True)\n",
    "    df2.trim.replace('DX-VP','DX',inplace=True)\n",
    "\n",
    "    # For exterior color\n",
    "    df2.exterior.replace('Taffeta White','White',inplace=True)\n",
    "    df2.exterior.replace('White Orchid','White',inplace=True)\n",
    "    df2.exterior.replace('Galaxy Gray Metallic','Gray',inplace=True)\n",
    "    df2.exterior.replace('Sonic Gray Pearl','Gray',inplace=True)\n",
    "    df2.exterior.replace('Dark Gray','Gray',inplace=True)\n",
    "    df2.exterior.replace('Ghost Gray','Gray',inplace=True)\n",
    "    df2.exterior.replace('Atomic Blue Metallic','Blue',inplace=True)\n",
    "    df2.exterior.replace('Aegean Blue Metallic','Blue',inplace=True)\n",
    "    df2.exterior.replace('Dyno Blue Pearl','Blue',inplace=True)\n",
    "    df2.exterior.replace('Royal Blue Pearl','Blue',inplace=True)\n",
    "    df2.exterior.replace('Dyno Blue Pearl Ii','Blue',inplace=True)\n",
    "\n",
    "    # Add a category 'Other' to merge the minor categories\n",
    "    index_exterior = df2.exterior.value_counts()[:8]\n",
    "    for i in range(len(df2)):\n",
    "        if df2.exterior[i] not in index_exterior:\n",
    "            df2.exterior.replace(df2.exterior[i],'Other',inplace=True)\n",
    "    index_interior = df2.interior.value_counts()[:9]\n",
    "    for i in range(len(df2)):\n",
    "        if df2.interior[i] not in index_interior:\n",
    "            df2.interior.replace(df2.interior[i],'Other',inplace=True)\n",
    "    return df2\n",
    "\n",
    "df2 = data_clean_category(df):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy variables for categorical data and adding more complexity for numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummy_poly_feature(df2):\n",
    "    X=df2[['year','miles']]\n",
    "\n",
    "    # Generate dummy variables for categorical data\n",
    "    dummy_trim=pd.get_dummies(df2.trim, prefix='trim')#, drop_first=True)\n",
    "    dummy_exterior=pd.get_dummies(df2.exterior, prefix='exterior')#, drop_first=True)\n",
    "    dummy_interior=pd.get_dummies(df2.interior, prefix='interior')#, drop_first=True)\n",
    "    dummy_transmission=pd.get_dummies(df2.transmission, prefix='transmission')#, drop_first=True)\n",
    "\n",
    "    X = X.join(dummy_trim)\n",
    "    X = X.join(dummy_exterior)\n",
    "    X = X.join(dummy_interior)\n",
    "    X = X.join(dummy_transmission)\n",
    "\n",
    "    y=df2.price.tolist()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,random_state=42)\n",
    "\n",
    "    # Log transformation for year and miles to remove the bias from data\n",
    "    X_train['year_log'] = np.log(X_train.year)\n",
    "    X_train['miles_log'] = np.log(X_train.miles)\n",
    "    X_train = X_train.drop(['year','miles'],axis=1)\n",
    "\n",
    "    X_test['year_log'] = np.log(X_test.year)\n",
    "    X_test['miles_log'] = np.log(X_test.miles)\n",
    "    X_test = X_test.drop(['year','miles'],axis=1)\n",
    "\n",
    "    # Adding more complexity for year and miles to account for nonlinear relationship\n",
    "    X2_train = X_train.filter(['year_log','miles_log'], axis=1)\n",
    "    X2_test = X_test.filter(['year_log','miles_log'], axis=1)\n",
    "\n",
    "    p = PolynomialFeatures(2)\n",
    "    X2_train = p.fit_transform(X2_train)\n",
    "    X2_test = p.transform(X2_test)\n",
    "\n",
    "    # Normalization (since the magnitude of miles are much higher than that of years)\n",
    "    s = StandardScaler()\n",
    "    X2_train_co = s.fit_transform(X2_train)\n",
    "    X2_test_co = s.transform(X2_test)\n",
    "\n",
    "    # Formatting data\n",
    "    col = ['col'+str(i) for i in range(6)]\n",
    "    X2_train_co = pd.DataFrame(columns=col, data=X2_train_co)\n",
    "    X2_test_co = pd.DataFrame(columns=col, data=X2_test_co)\n",
    "\n",
    "    X2_train_complex = pd.DataFrame.copy(X_train)\n",
    "    X2_test_complex = pd.DataFrame.copy(X_test)\n",
    "\n",
    "    X2_train_complex = X2_train_complex.reset_index(drop=True)\n",
    "    X2_test_complex = X2_test_complex.reset_index(drop=True)\n",
    "\n",
    "    X2_train_complex = X2_train_complex.join(X2_train_co)\n",
    "    X2_test_complex = X2_test_complex.join(X2_test_co)\n",
    "\n",
    "    X2_train_complex = X2_train_complex.drop(['year_log','miles_log'],axis=1)\n",
    "    X2_test_complex = X2_test_complex.drop(['year_log','miles_log'],axis=1)\n",
    "    X2_train_complex.col0.replace(0,1,inplace=True)\n",
    "\n",
    "    X2_train_complex.rename(columns={'col0': 'intercept', 'col1': 'year','col2':'mile','col3':'year_2','col4':'yearmile','col5':'mile_2'}, inplace=True)\n",
    "    \n",
    "    return X2_train_complex, y_train, X2_test_complex, y_test\n",
    "\n",
    "X2_train_complex, y_train, X2_test_complex, y_test = dummy_poly_feature(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regularization with Ridge regression\n",
    "est = make_pipeline(RidgeCV(cv=3,alphas=(1e-8,1e-4,1e0,1e4,1e8)))\n",
    "est.fit(X2_train_complex, y_train)\n",
    "\n",
    "print('Train R^2: ',est.score(X2_train_complex, y_train))\n",
    "print('Train RMSSE:', np.sqrt(mean_squared_error(y_train, est.predict(X2_train_complex))))\n",
    "print('Test R^2: ', est.score(X2_test_complex, y_test))\n",
    "print('Test RMSSE:', np.sqrt(mean_squared_error(y_test, est.predict(X2_test_complex))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.scatter(y_test, est.predict(X2_test_complex), label='Data')\n",
    "a=[0,25000]\n",
    "b=[0,25000]\n",
    "plt.plot(a,b, color='red', label='Perfect match')\n",
    "plt.title('Price Prediction', fontsize=30)\n",
    "plt.xlabel('Actual Price ($)',fontsize=20)\n",
    "plt.ylabel('Predicted Price ($)',fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.scatter(est.predict(X2_train_complex), est.predict(X2_train_complex) - y_train, c='b',alpha = 0.5, label='Train')\n",
    "plt.scatter(est.predict(X2_test_complex), est.predict(X2_test_complex) - y_test, c='g',alpha = 0.5, label='Test')\n",
    "plt.title('Residual scatter plot for Train (blue) and Test (green) data', fontsize=30)\n",
    "plt.xlabel('Predicted Price ($)',fontsize=20)\n",
    "plt.ylabel('Residual ($)',fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlim([-5000,25000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate p-values with Statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p_value(X_train, y_train):\n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    stats_y = pd.DataFrame(y_train, columns=['price'])\n",
    "    X_train = X_train.join(stats_y)\n",
    "\n",
    "    # Generate equations for Statsmodel\n",
    "    equ='price ~ ' + str(X_train.columns[0])\n",
    "    for i in range(1,X_train.shape[1]-1):\n",
    "        equ += ' + '\n",
    "        equ += str(X_train.columns[i])\n",
    "\n",
    "    y, X = patsy.dmatrices(equ, data=X_train, return_type=\"dataframe\")\n",
    "    model = sm.OLS(y, X)\n",
    "    fit = model.fit()\n",
    "\n",
    "    return fit.summary()\n",
    "\n",
    "p_value((X2_train_complex, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study with different degrees of polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def poly_features(df2):\n",
    "    r2_train=[]\n",
    "    r2_test=[]\n",
    "    rmse_train=[]\n",
    "    rmse_test=[]\n",
    "    index=[]\n",
    "    \n",
    "    X=df2[['year','miles']]\n",
    "\n",
    "    # Generate dummy variables for categorical data\n",
    "    dummy_trim=pd.get_dummies(df2.trim, prefix='trim')#, drop_first=True)\n",
    "    dummy_exterior=pd.get_dummies(df2.exterior, prefix='exterior')#, drop_first=True)\n",
    "    dummy_interior=pd.get_dummies(df2.interior, prefix='interior')#, drop_first=True)\n",
    "    dummy_transmission=pd.get_dummies(df2.transmission, prefix='transmission')#, drop_first=True)\n",
    "\n",
    "    X = X.join(dummy_trim)\n",
    "    X = X.join(dummy_exterior)\n",
    "    X = X.join(dummy_interior)\n",
    "    X = X.join(dummy_transmission)\n",
    "\n",
    "    y=df2.price.tolist()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4,random_state=42)\n",
    "\n",
    "    for k in range(2,10):  # Exploring different degrees from 2 to 9\n",
    "        p = PolynomialFeatures(k)\n",
    "        \n",
    "        X_train = p.fit_transform(X_train)\n",
    "        X_test = p.transform(X_test)\n",
    "        s = StandardScaler()\n",
    "        X1_train_co = s.fit_transform(X_train)\n",
    "        X1_test_co = s.transform(X_test)\n",
    "        X2_train_co = pd.DataFrame(data=X1_train_co) #columns=col\n",
    "        X2_test_co = pd.DataFrame(data=X1_test_co) #columns=col\n",
    "        X2_train_complex = pd.DataFrame.copy(X_train)\n",
    "        X2_test_complex = pd.DataFrame.copy(X_test)\n",
    "        X2_train_complex = X2_train_complex.reset_index(drop=True)\n",
    "        X2_test_complex = X2_test_complex.reset_index(drop=True)\n",
    "        X2_train_complex = X2_train_complex.join(X2_train_co)\n",
    "        X2_test_complex = X2_test_complex.join(X2_test_co)\n",
    "        X2_train_complex = X2_train_complex.drop(['year_log','miles_log'],axis=1)\n",
    "        X2_test_complex = X2_test_complex.drop(['year_log','miles_log'],axis=1)\n",
    "\n",
    "        est = make_pipeline(RidgeCV(cv=3,alphas=(1e-8,1e-4,1e0,1e4,1e8)))\n",
    "\n",
    "        est.fit(X2_train_complex, y_train)\n",
    "        print('complexity =', k)\n",
    "        print('Train R^2: ',est.score(X2_train_complex, y_train))\n",
    "        print('Train RMSE:', np.sqrt(mean_squared_error(y_train, est.predict(X2_train_complex))))\n",
    "        print('Test R^2: ', est.score(X2_test_complex, y_test))\n",
    "        print('Test RMSE:', np.sqrt(mean_squared_error(y_test, est.predict(X2_test_complex))))\n",
    "        print('----------')\n",
    "\n",
    "        r2_train.append(est.score(X2_train_complex, y_train))\n",
    "        r2_test.append(est.score(X2_test_complex, y_test))\n",
    "        rmse_train.append(np.sqrt(mean_squared_error(y_train, est.predict(X2_train_complex))))\n",
    "        rmse_test.append(np.sqrt(mean_squared_error(y_test, est.predict(X2_test_complex))))\n",
    "        index.append(k)\n",
    "        return r2_train, r2_test, rmse_train, rmse_test, index\n",
    "\n",
    "r2_train, r2_test, rmse_train, rmse_test, index = poly_features(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wife_car_final=np.array([1,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,1,-0.5111072,  0.65581954, -0.51126046,  0.65604447,0.64537731])\n",
    "np.dot(fit.params,wife_car_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
